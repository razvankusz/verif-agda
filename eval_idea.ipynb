{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Counting Usage of Lemmas \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This script attempts to evaluate the project \n",
    "\n",
    "The first stage is finding the usage of lemmas towards the declaration\n",
    "\n",
    "A further step is to score the difficulty of lemmas given their counts of the basic lemmas\n",
    "    refl\n",
    "    sym\n",
    "    trans\n",
    "    cong \n",
    "    ε-right\n",
    "    ε-left \n",
    "    ∙-assoc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "agda_file_location = 'agda-playground/fingertree/FingerTree-measure-size-c.agda'\n",
    "#agda_file_location = 'agda-playground/fingertree/list-reverse-proof.agda'\n",
    "\n",
    "#requirements are that all declarations are separated by at least a newline\n",
    "\n",
    "#as a styling techinique to make this easier:\n",
    "# all lemmas contain the word lemma\n",
    "# lemmas that are derived through the monoid solver have a dash (') at the end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# regular expressions\n",
    "\n",
    "#comment in the begining\n",
    "comment_begining = r'^\\s*--'\n",
    "\n",
    "#imports \n",
    "imports_begining = r'^(\\s*open)|(\\s*open\\s*import)|(\\s*import)'\n",
    "\n",
    "#infixation\n",
    "infix_begining = r'^\\s*infix[lr]*'\n",
    "\n",
    "#instance\n",
    "instance_begining = r'^\\s*instance'\n",
    "\n",
    "#data\n",
    "data_begining = r'^\\s*data'\n",
    "\n",
    "#mutual\n",
    "mutual_begining = r'^\\s*mutual'\n",
    "\n",
    "#module \n",
    "module = r'^\\s*module'\n",
    "\n",
    "#declarations\n",
    "decl = r'^\\s*(postulate){0,1}\\s*([^\\s:]+)\\s*:'\n",
    "\n",
    "#lemmas \n",
    "lemmas = [r'refl',\n",
    "          r'sym',\n",
    "          r'cong',\n",
    "          r'≡⟨',          \n",
    "          r'ε-left',\n",
    "          r'ε-right',\n",
    "          r'∙-assoc',\n",
    "          r'[^\\s:\\(]+lemma[^\\s:\\)]*',    #two ways through which\n",
    "          r'[^\\s:\\(]+correct[^\\s:\\)]*']  #I identify lemmas in the src.\n",
    "\n",
    "#lemma building blocks.\n",
    "basic_lemmas = [r'refl',\n",
    "          r'sym',\n",
    "          r'cong',\n",
    "          r'≡⟨',     #this is equivalent to a trans application\n",
    "          r'ε-left',\n",
    "          r'ε-right',\n",
    "          r'∙-assoc']\n",
    "\n",
    "\n",
    "#for pretty printing\n",
    "basic_lemmas_names = [r'refl',\n",
    "          r'sym',\n",
    "          r'cong',\n",
    "          r'trans',    \n",
    "          r'ε-left',\n",
    "          r'ε-right',\n",
    "          r'∙-assoc']                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "agda_file = codecs.open(agda_file_location, 'r', encoding='utf-8')\n",
    "lines = agda_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def remove_all_lines(reg, lines):\n",
    "    filter_fun = lambda x : (re.match(reg, x) == None)\n",
    "    return [x for x in lines if filter_fun(x)]\n",
    "\n",
    "def remove_ending_comment(line):\n",
    "    return line.split('--')[0]\n",
    "\n",
    "def strip_ending_comments(lines):\n",
    "    return [remove_ending_comment(x) for x in lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#preprocessing the lines -- decluttering the document \n",
    "\n",
    "\n",
    "lines = remove_all_lines(comment_begining, lines)\n",
    "lines = remove_all_lines(imports_begining, lines)\n",
    "lines = remove_all_lines(infix_begining, lines)\n",
    "lines = remove_all_lines(mutual_begining, lines)\n",
    "lines = remove_all_lines(module, lines)\n",
    "lines = strip_ending_comments(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# at least * all top level declarations \n",
    "#these are toplogically sorted\n",
    "\n",
    "declarations = [re.search(decl, x).group(1) for x in lines if re.search(decl,x) is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#splitting in sections \n",
    "\n",
    "new_lines = [i for (i, x) in enumerate(lines) if x == u'\\n']\n",
    "\n",
    "#partition to sections\n",
    "#that is, each section corresponds to a declaration\n",
    "def partition(new_lines, lines):\n",
    "    parts = []\n",
    "    N = len (new_lines)\n",
    "    for i in range(1, N):\n",
    "        parts.append(lines[new_lines[i-1] + 1 : new_lines[i]])\n",
    "    return parts\n",
    "\n",
    "parts = partition(new_lines, lines)\n",
    "\n",
    "#remove empty lists \n",
    "parts = [x for x in parts if len(x) > 0]\n",
    "\n",
    "#select only sections that are not data declarations\n",
    "#we are only interested in function declarations\n",
    "def select_parts_begining(regex, parts):\n",
    "    filter_fun = lambda x : (re.match(regex, x[0]) == None) \n",
    "    return [x for x in parts if filter_fun(x)]\n",
    "\n",
    "decl_parts = select_parts_begining(data_begining, parts)\n",
    "\n",
    "#select all sections that are not instance declarations -- makes things easier\n",
    "decl_parts = select_parts_begining(instance_begining, decl_parts)\n",
    "\n",
    "#identify declarations in each part\n",
    "def parts_dict(parts):\n",
    "    p_dict = {}\n",
    "    for part in parts:\n",
    "        line = part[0]\n",
    "        decl_match = re.search(decl, line)\n",
    "        if (decl_match is None):\n",
    "            print part\n",
    "        declr = decl_match.group(2)\n",
    "        assert declr not in p_dict\n",
    "        p_dict[declr] = part\n",
    "    return p_dict\n",
    "\n",
    "# find all the lemmas used in a declaration(part)\n",
    "def find_lemmas(decl, part):\n",
    "    #outputs {n_lines, rec, lemmas}\n",
    "    results = []    \n",
    "    n_lines = len(part)\n",
    "    rec = False \n",
    "    \n",
    "    for regex in lemmas:\n",
    "        for line in part:\n",
    "            results += re.findall(regex, line)\n",
    "        #    print results\n",
    "    results = [x for x in results if not (x == decl)]\n",
    "    \n",
    "    #find whether it is recursive -- TODO    \n",
    "    rec_regex = r'\\s+[^\\s]+\\s+' + decl\n",
    "    # don't want the declaration to appear at new line, \n",
    "    # because that's just caused by initialisation    \n",
    "    rec_list = []\n",
    "    for line in part: \n",
    "        rec_list += re.findall(rec_regex, line)        \n",
    "    if rec_list is not []:\n",
    "        rec = True;\n",
    "        \n",
    "    return {'n_lines' : n_lines, 'rec' : rec, 'lemmas' : results}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "decl_dict = parts_dict(decl_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lemma_dict(decl_dict):\n",
    "    result = {}\n",
    "    for key in decl_dict:\n",
    "        result[key] = find_lemmas(key, decl_dict[key])['lemmas']\n",
    "    return result\n",
    "\n",
    "\n",
    "# other lemmas stats\n",
    "\n",
    "def declaration_stats(decl_dict):\n",
    "    result = {}\n",
    "    for key in decl_dict:\n",
    "        lemma_stat = find_lemmas(key, decl_dict[key])\n",
    "        result[key] = lemma_stat['n_lines'], lemma_stat['rec']\n",
    "    result = pd.DataFrame.from_dict(result, 'index')\n",
    "    result.columns = ['n_lines', 'rec']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'refl',\n",
       " u'refl',\n",
       " u'refl',\n",
       " u'sym',\n",
       " u'sym',\n",
       " u'cong',\n",
       " u'cong',\n",
       " u'cong',\n",
       " u'\\u2261\\u27e8',\n",
       " u'\\u2261\\u27e8',\n",
       " u'\\u2261\\u27e8',\n",
       " u'\\u2261\\u27e8',\n",
       " u'\\u2261\\u27e8',\n",
       " u'\\u2261\\u27e8',\n",
       " u'flatten-fold-lemma',\n",
       " u'foldl-append-lemma2',\n",
       " u'foldl-dig-correct',\n",
       " u'foldl-dig-correct']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_usage = lemma_dict(decl_dict)\n",
    "lemma_usage['foldl-correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#this fills up automatically because of memoisation\n",
    "flattened_lemmas = {}\n",
    "\n",
    "def flatten_list(l):\n",
    "    result = []\n",
    "    if type(element) is str:\n",
    "        result.append(element)\n",
    "    else:\n",
    "        result += element\n",
    "    return result\n",
    "\n",
    "def flatten_lemma(decl, lemma_dict):\n",
    "    if decl in flattened_lemmas:\n",
    "        return flattened_lemmas[decl]\n",
    "    \n",
    "    if decl in lemma_dict:\n",
    "        used_lemmas = lemma_dict[decl]\n",
    "    else:\n",
    "        used_lemmas = []\n",
    "        \n",
    "    for (i, lemma) in enumerate(used_lemmas):\n",
    "        if lemma not in basic_lemmas:\n",
    "            flat = flatten_lemma(lemma, lemma_dict)\n",
    "            used_lemmas[i:i+1] = flat\n",
    "             \n",
    "    flattened_lemmas[decl] = used_lemmas\n",
    "    return used_lemmas    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def flatten_dict(lemma_usage):\n",
    "    for key in lemma_usage:\n",
    "        flatten_lemma(key, lemma_usage)\n",
    "\n",
    "flatten_dict(lemma_usage)\n",
    "\n",
    "lemma_dict = flattened_lemmas\n",
    "\n",
    "\n",
    "# normalizes a lemma list as a frequency vector of basic lemmas usage\n",
    "def normalize_lemma_vec(lemmas):\n",
    "    result = np.zeros(len(basic_lemmas))\n",
    "    for lemma in lemmas:\n",
    "        if lemma in basic_lemmas:\n",
    "            i = basic_lemmas.index(lemma)\n",
    "            result[i] += 1\n",
    "    return result\n",
    "\n",
    "# normalize the whole dictionary\n",
    "def normalize_lemma_dict(lemma_dict):\n",
    "    result = {}\n",
    "    for key in lemma_dict:\n",
    "        result[key] = normalize_lemma_vec(lemma_dict[key])\n",
    "    return result\n",
    "\n",
    "# alternative lemma dictionary with unique lemmas\n",
    "def all_lemma_dict(lemma_dict):\n",
    "    result = {}\n",
    "    for key in lemma_dict:\n",
    "        result[key] = set(lemma_dict[key])\n",
    "    return result\n",
    "\n",
    "norm_lemma_dict = normalize_lemma_dict(lemma_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "refl       3\n",
       "sym        5\n",
       "cong       1\n",
       "trans      6\n",
       "ε-left     4\n",
       "ε-right    2\n",
       "∙-assoc    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to find a way to analyze this data\n",
    "df_lemmas = pd.DataFrame.from_dict(norm_lemma_dict, orient='index', dtype=int)\n",
    "df_lemmas.columns = basic_lemmas_names\n",
    "df_lemmas.loc['deepL'] + df_lemmas.loc['viewL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'FunExt': set(),\n",
       " u'_\\u25b7_': {u'cong',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'_\\u25c1_': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'append': {u'cong',\n",
       "  u'refl',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'append-measure-lemma': {u'cong', u'refl', u'\\u2219-assoc', u'\\u2261\\u27e8'},\n",
       " u'assoc-lemma1': {u'cong', u'sym', u'\\u03b5-left'},\n",
       " u'assoc-lemma2': {u'cong', u'refl', u'sym', u'\\u2219-assoc', u'\\u2261\\u27e8'},\n",
       " u'assoc-lemma3': {u'sym', u'\\u03b5-left', u'\\u2219-assoc', u'\\u2261\\u27e8'},\n",
       " u'assoc-lemma4': {u'sym', u'\\u03b5-left', u'\\u2219-assoc', u'\\u2261\\u27e8'},\n",
       " u'assoc-lemma5': {u\"assoc-lemma5'\"},\n",
       " u'assoc-lemma6': {u\"assoc-lemma6'\"},\n",
       " u'assoc-lemma7': {u\"assoc-lemma7'\"},\n",
       " u'assoc-lemma8': {u\"assoc-lemma8'\"},\n",
       " u'assoc-lemma9': {u\"assoc-lemma9'\"},\n",
       " u'concat': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'cons-correct': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'deepL': {u'sym', u'\\u03b5-left', u'\\u2219-assoc', u'\\u2261\\u27e8'},\n",
       " u'deepR': {u'cong',\n",
       "  u'refl',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'deepr-measure-lemma1': {u'cong', u'refl', u'\\u03b5-right', u'\\u2261\\u27e8'},\n",
       " u'deepr-measure-lemma2': {u'cong', u'refl', u'\\u03b5-right', u'\\u2261\\u27e8'},\n",
       " u'ex-ft': set(),\n",
       " u'flatten-fold-lemma': {u'cong',\n",
       "  u'foldl-node-correct',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'flatten-list': set(),\n",
       " u'fold-monoid-lemma': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'foldfun': set(),\n",
       " u'foldfun-lemma': {u'cong',\n",
       "  u'refl',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'foldfun-list': set(),\n",
       " u'foldfun-node': set(),\n",
       " u'foldl': set(),\n",
       " u'foldl-correct': {u'cong',\n",
       "  u'foldl-dig-correct',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'foldl-dig': set(),\n",
       " u'foldl-dig-correct': {u'refl'},\n",
       " u'foldl-dig-lemma0': {u\"assoc-lemma5'\",\n",
       "  u\"assoc-lemma6'\",\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u2219-assoc'},\n",
       " u'foldl-lemma0': {u\"assoc-lemma5'\",\n",
       "  u\"assoc-lemma6'\",\n",
       "  u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'foldl-node': set(),\n",
       " u'foldl-node-correct': {u'refl'},\n",
       " u'foldl-node-lemma0': {u\"assoc-lemma5'\", u'refl', u'sym', u'\\u2219-assoc'},\n",
       " u'foldl-node-lemma1': {u'refl', u'sym', u'\\u2219-assoc'},\n",
       " u'foldr': set(),\n",
       " u'foldr-dig': set(),\n",
       " u'foldr-node': set(),\n",
       " u'head-dig': set(),\n",
       " u'headL': {u'refl'},\n",
       " u'heads-dig': set(),\n",
       " u'lemma6': {u'refl', u'\\u2261\\u27e8'},\n",
       " u'measure-dig-lemma0': {u'refl', u'\\u03b5-right'},\n",
       " u'measure-digit': set(),\n",
       " u'measure-digit-lemma1': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'measure-digit-lemma2': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'measure-digit-rev': set(),\n",
       " u'measure-lemma0': {u'cong',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'measure-lemma1': {u'\\u03b5-left', u'\\u2261\\u27e8'},\n",
       " u'measure-list': set(),\n",
       " u'measure-list-lemma': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'measure-maybe-digit': set(),\n",
       " u'measure-node': set(),\n",
       " u'measure-node-digit-lemma': set(),\n",
       " u'measure-rev': set(),\n",
       " u'measure-rev-list': set(),\n",
       " u'measure-split-digit': set(),\n",
       " u'measure-to-tree-maybe-dig-lemma': {u'refl'},\n",
       " u'measure-tree': set(),\n",
       " u'node2': {u'refl'},\n",
       " u'node3': {u'refl'},\n",
       " u'prop-monoid-lemma': {u'cong', u'refl', u'sym', u'\\u03b5-right'},\n",
       " u'rev-digit': set(),\n",
       " u'rev-node': set(),\n",
       " u'snoc-assoc-lemma1': {u'cong', u'sym', u'\\u2219-assoc', u'\\u2261\\u27e8'},\n",
       " u'snoc-assoc-lemma2': {u'cong', u'sym', u'\\u2219-assoc', u'\\u2261\\u27e8'},\n",
       " u'snoc-assoc-lemma3': {u'cong', u'sym', u'\\u2219-assoc', u'\\u2261\\u27e8'},\n",
       " u'snoc-assoc-lemma4': {u'cong', u'sym', u'\\u2219-assoc', u'\\u2261\\u27e8'},\n",
       " u'split-Tree': {u'refl'},\n",
       " u'split-Tree-if': {u'sym'},\n",
       " u'split-Tree-single': {u'sym', u'\\u03b5-left', u'\\u03b5-right'},\n",
       " u'split-Tree1': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'split-Tree1-measure-lemma': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'split-Tree2': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'split-Tree2-measure-lemma': {u\"assoc-lemma8'\",\n",
       "  u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'split-Tree3': {u'cong',\n",
       "  u'refl',\n",
       "  u'structure-measure-lemma1',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'split-Tree3-measure-lemma': {u\"assoc-lemma9'\",\n",
       "  u'cong',\n",
       "  u'splitDigit-size-lemma0',\n",
       "  u'sym',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'split-lemma-empty': {u'refl'},\n",
       " u'splitDigit': set(),\n",
       " u'splitDigit-size-lemma0': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'structure-measure-lemma0': {u'cong', u'refl', u'sym', u'\\u03b5-right'},\n",
       " u'structure-measure-lemma1': {u'cong', u'refl', u'sym', u'\\u03b5-right'},\n",
       " u'tail-dig': set(),\n",
       " u'tailL': {u'refl'},\n",
       " u'tails-dig': set(),\n",
       " u'toDigit': set(),\n",
       " u'toList-dig': set(),\n",
       " u'toList-ft': set(),\n",
       " u'toList-ft-measure-correct': {u'cong',\n",
       "  u'foldl-correct',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'toList-maybe-dig': set(),\n",
       " u'toList-node': set(),\n",
       " u'toList-view': set(),\n",
       " u'toList1': set(),\n",
       " u'toTree-dig': {u'cong', u'sym', u'\\u03b5-right'},\n",
       " u'toTree-maybe-dig': set(),\n",
       " u'viewL': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'viewR': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'viewl-correct': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'viewl-to-ft': set(),\n",
       " u'viewr-deep-measure-lemma': {u'cong',\n",
       "  u'refl',\n",
       "  u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u2219-assoc',\n",
       "  u'\\u2261\\u27e8'},\n",
       " u'\\u03b5-comm-lemma': {u'sym',\n",
       "  u'\\u03b5-left',\n",
       "  u'\\u03b5-right',\n",
       "  u'\\u2261\\u27e8'}}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lemma_dict(lemma_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "≡⟨\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
